{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98fe97d4-7e02-4456-af46-c2397c38c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline, StableDiffusionXLPipeline, DPMSolverMultistepScheduler, UNet2DConditionModel, AutoencoderKL\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, AutoTokenizer\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from accelerate import Accelerator\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed570931-9fdd-4cbe-89a9-d37b6a1223a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b198bddd19f74b18a9235c5dec9c1e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cc36213e2f44658f5fdfe43e60c84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb9fef93c0e4d438cb1d9e0601da0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc9d6c30dec4f7989e6143b11e73be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6db3b16f95404a9086d804f861f4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108f43df9d0f470fb970f4f8598b11bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6252ae7f4aa443cbbe63c28ead53a1a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6520c730-fa2e-45f1-8aa8-20fc6c65c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    caption = model.generate(**inputs)\n",
    "    return processor.decode(caption[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8634a785-740a-427e-9055-3538071c2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p03.jpg: gnome with a flower and butterfly on a white background\n",
      "p06.jpg: a black and white drawing of a hand with a triangle and all seeing symbols\n",
      "ghouldfriend_p01.png: a close up of a black bat with big eyes and a big nose\n",
      "p02.jpg: cartoon illustration of a bee with a pot of honey\n",
      "p12.png: two wooden nutcrackers with pine cones and hollyconnets on them\n",
      "p10.jpg: there is a snowman with a hat and scarf holding a present\n",
      "p01.jpg: gnome with a butterfly on his head holding a flower pot\n",
      "p11.jpg: a close up of a toy figure of a cat with a cup\n",
      "p09.jpg: there is a snowman with a scarf and hat holding a red ribbon\n",
      "p08.jpg: a close up of a penguin with a christmas present on a calendar\n",
      "p04.jpg: a close up of a halloween candle holder with a witch hat on top\n",
      "p05.jpg: there are three pumpkins stacked on top of each other\n",
      "p07.jpg: a close up of a skeleton hand holding a skull on a stand\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"datasets/designs/\"\n",
    "caption_file = \"datasets/caption.txt\"\n",
    "for img in os.listdir(image_folder):\n",
    "    caption = generate_caption(os.path.join(image_folder, img))\n",
    "    print(f\"{img}: {caption}\")\n",
    "    with open(caption_file, \"a\") as f:\n",
    "        f.write(f'{img}\\t{caption}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
